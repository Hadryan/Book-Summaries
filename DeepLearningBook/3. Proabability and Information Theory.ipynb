{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Book: Probabilty and Information Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In probability theory, an **event** is a set of outcomes of an **experiment** to which a **probability** is assigned. If **E** represents an event, then **P(E)** represents the probability that E will occur. A situation where E might happen (success) or might not happen (failure) is called a **trial**. When we say that an outcome has a probability p of occurring, it means that if we repeated the experiment infinitely many times, then proportion p of the repetitions would result in that outcome. According to the book, nearly all activities require some ability to reason in the presence of uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chapter is divided into following sections and subsections "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Why Probability\n",
    "* Random Variables\n",
    "* Probability Distributions\n",
    "    * Discrete Variables and Probability Mass Functions\n",
    "    * Continuous Variables and Probablity Density Functions\n",
    "* Marginal Probability\n",
    "* Conditional Proability\n",
    "* The Chain rule of Conditional Probabilities\n",
    "* Independence or Conditional Independence\n",
    "* Expectation, Variance and Covariance\n",
    "* Common Probability Distributions\n",
    "    * Bernoulli\n",
    "    * Multinoulli\n",
    "    * Gaussian\n",
    "    * Exponential and Laplace Distributions\n",
    "    * The Dirac Distributiona and Empirical Distribution\n",
    "    * Mixtures of Distribution\n",
    "* Useful properties of Common Functions\n",
    "* Baye's Rule\n",
    "* Technical Details of Continuous Variables\n",
    "* Information Theory\n",
    "* Structured Probablistic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Why Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, very few things are certain. So Machine Learning models should reason using probabilistic rules. In the language of the book, machine learning must always deal with uncertain quantities and sometimes stochastic (nondeterministic) quantities. Uncertainty and stochasticity can arise from many sources.  The three possible sources are:\n",
    "\n",
    "1. Inherent Stochasticity in the system being modelled: A situation where the outcome is really random. For e.g, say we have a language model which predicts the next word in the sentence. For it, a sentence like *Github is ___* is difficult because the next word can be anything\n",
    "\n",
    "2. Imcomplete observability: For example, in the Monty Hall problem, the outcome given the contestant’s choice is deterministic, but from the contestant’s point of view, the outcome is uncertain.\n",
    "\n",
    "3. Incomplete modeling. When we use a model that must discard some ofthe information we have observed, the discarded information results inuncertainty in the model’s predictions. \n",
    "\n",
    "In many cases, it is more practical to use a simple but uncertain rule ratherthan a complex. The book gives a great example of birds. It makes more sense to remember “most birds can fly” than “all birds can fly except sick, injured or very young birds etc.”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a probability related directly to the rates at which events occur, this probability known as **Frequentist probability** (deal the cards).\n",
    "\n",
    "If probability related to qualitative levels of certainty, it’s known as **Bayesian probability** (have patient flue or not). In such a case we'll have a **degree of belief**, with 1 indicating absolute certainty that the patient has the flu and 0 indicating absoluting certainty that the patient doesn't have the flu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random variableis a variable that can take on diﬀerent values randomly (Can't be more obvious :P). \n",
    "\n",
    "Random variables may be **discrete** or **continuous**. A discrete random variable is one that has a finite or countably infinite number of states. Note that these states are not necessarily the integers; they can also just be named states that are not considered to have any numerical value. A continuous random variable is associated with a real value\n",
    "\n",
    "On its own, a random variable is just a description of the states that are possible; it must be coupled with a **probability distribution** that speciﬁes how likely each of these states are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A probability distribution is a description of how likely a random variable or set of random variables is to take on each of its possible states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Discrete Variables and Probability Mass Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A probability distribution over ***discrete variables*** may be described using a **probability mass function(PMF)**.The probability mass function maps from a state of a random variable tothe probability of that random variable taking on that state.\n",
    "\n",
    "Probability mass functions can act on many variables at the same time. Such a probability distribution over many variables is known as a **joint probability distribution**.P(x=*x*, y=*y*) denotes the probability that x=*x* and y=*y* simultaneously. We may also write P (*x*, *y*) for brevity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be a PMF on a random variable x, a function P must satisfy the following properties:\n",
    "* The domain of P must be the set of all possible states of x.\n",
    "* ∀*x* $\\epsilon$ x,0≤ P(*x*)≤1.\n",
    "* $\\sum_{\\varkappa \\epsilon x}$ **P(*x*)** = 1 (Normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, a single discrete random variable x with k different states. In a uniform distribution on x by setting PMF to         \n",
    "P(x = $\\varkappa_i$) = 1/k for all i. We can also see that this is normalized since adding up them all results in 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Continuous Variables and Probability Density Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ***continuous random variables***, we describe probability distributions using a **probability density function(PDF)**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be a PDF, a function *p* must satisfy the following properties:\n",
    "* The domain of *p* must be the set of all possible states of x.\n",
    "* $\\forall$*x* $\\epsilon$ x, p(*x*) ≥ 0. Note that we do not require p(x) ≤ 1.\n",
    "* $\\int$p(*x*) d*x* = 1\n",
    "\n",
    "\n",
    "A probability density function p(*x*) does not give the probability of a speciﬁc state directly; instead the probability of landing inside an inﬁnitesimal region withvolume δ*x* is given by p(*x*)δ*x*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Marginal Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginal probability is the probability distribution over a **subset of a set**.\n",
    "Suppose we know P(x,y) for discrete random variables x and y. We can find P(x) with the sum rule: ∀*x*∈x,P(x)=∑yP(x=*x*,y=*y*).\n",
    "\n",
    "For continuous variables, we need to use integration instead of summation: p(x)=∫p(x,y)dy\n",
    "\n",
    "When the values of P(x,y) are written in a grid with different values of x in rows and different values of y in columns, it is natural to sum across a row of the grid, then write P(x) in the margin of the paper just to the right of the row.(ref. figure below)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://www.statisticshowto.datasciencecentral.com/wp-content/uploads/2014/02/marginal-distributions-1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Conditional Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginalization allows us to get the distribution of variable X ignoring variable Y from the joint distribution of X and Y, but what if we want to know the distribution of X given a specific value of Y? Conditional Probability is the probability of **some event X, given that some other event Y has happened**. It is denoted by $P(X \\hspace{.1cm}| \\hspace{.1cm} Y)$ such that \n",
    "$$ P(\\text{y} = y \\hspace{.1cm}| \\hspace{.1cm} \\text{x} = x) = \\frac{P(\\text{y} = y , \\text{x} = x)}{P(\\text{x} = x)} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give an example, suppose you know that Jens can speak Germany but want to know the probability that he belongs to Germany. In such a case, you'll make use of conditional probability.\n",
    "\n",
    "however, note that conditional probability does not imply causation. To take a common example from Pearl & Mackenzie, the probability of the sun rising, given that the rooster has crowed, is high. But in no way implies that the rooster's crowing causes the sun to rise.\n",
    "\n",
    "More precisely, the conditional probability holds under the assumption of observation without intervention. **If we observe the rooster crowing without having intervened and forcing it to crow, there is a good chance that the sun has risen. But if we intervene by forcing the rooster to crow, the crowing is no longer related to the sunrise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. The Chain Rule of Conditional Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any joint probability distribution over many random variables may be decomposed into conditional distributions over only one variable. \n",
    "The general expression is given by: $$P(\\text{x}^{(1)}, ..., \\text{x}^{(n)}) = P(\\text{x}^{(1)}) \\prod_{i=2}^{n} P(\\text{x}^{(i)} \\hspace{.1cm} | \\hspace{.1cm} \\text{x}^{(1)},..., \\text{x}^{(i-1)}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.Independence and Conditional Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two random variables x & y are said to be **independent** (x $\\perp$ y) if they satisfy: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\forall x \\in \\text{x}, y \\in \\text{y}, P(\\text{x} = x, \\text{y} = y) = P(\\text{x} = x)P(\\text{y} = y) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
